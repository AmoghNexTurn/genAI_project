{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10639283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import requests\n",
    "import streamlit as st\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "import pdfplumber\n",
    "from docx import Document\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv, dotenv_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82746b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, dotenv_values \n",
    "load_dotenv()\n",
    "\n",
    "GROQ_MODEL = \"meta-llama/llama-4-scout-17b-16e-instruct\"\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd50caf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(text, window_size=1000, overlap=500):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + window_size\n",
    "        chunks.append(text[start:end])\n",
    "        if end >= len(text):\n",
    "            break\n",
    "        start += window_size - overlap\n",
    "    return chunks\n",
    "\n",
    "def chunk_file(file_path, row_chunk_size=10):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    file_name = os.path.basename(file_path)\n",
    "    chunks = []\n",
    "\n",
    "    def make_payloads(text_chunks):\n",
    "        return [{\"text\": chunk, \"file\": file_name} for chunk in text_chunks]\n",
    "\n",
    "    if ext == \".txt\":\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "        chunks = make_payloads(sliding_window(text))\n",
    "\n",
    "    elif ext == \".docx\":\n",
    "        doc = Document(file_path)\n",
    "        full_text = \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "        chunks = make_payloads(sliding_window(full_text))\n",
    "\n",
    "    elif ext == \".pdf\":\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            full_text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                full_text += (page.extract_text() or \"\") + \"\\n\"\n",
    "        chunks = make_payloads(sliding_window(full_text))\n",
    "\n",
    "    elif ext == \".json\":\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        if isinstance(data, list):\n",
    "            text_chunks = [json.dumps(item, ensure_ascii=False) for item in data]\n",
    "        elif isinstance(data, dict):\n",
    "            text_chunks = [json.dumps({k: v}, ensure_ascii=False) for k, v in data.items()]\n",
    "        else:\n",
    "            text_chunks = [json.dumps(data, ensure_ascii=False)]\n",
    "        chunks = make_payloads(text_chunks)\n",
    "\n",
    "    elif ext == \".xml\":\n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "        text_chunks = [ET.tostring(elem, encoding='unicode') for elem in root]\n",
    "        chunks = make_payloads(text_chunks)\n",
    "\n",
    "    elif ext in [\".csv\", \".xlsx\"]:\n",
    "        if ext == \".csv\":\n",
    "            df = pd.read_csv(file_path)\n",
    "        else:\n",
    "            df = pd.read_excel(file_path)\n",
    "\n",
    "        text_chunks = []\n",
    "        for i in range(0, len(df), row_chunk_size):\n",
    "            chunk_df = df.iloc[i:i + row_chunk_size]\n",
    "            text_chunks.append(chunk_df.to_csv(index=False, lineterminator='\\n'))\n",
    "        chunks = make_payloads(text_chunks)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file extension: {ext}\")\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a2d9e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: battery_technology_data.xlsx, Chunks: 10\n",
      "File: battery_tech_unique_data.json, Chunks: 110\n",
      "File: graphene_battery.txt, Chunks: 160\n",
      "File: how_lithium_ion_batteries_work_doj.pdf, Chunks: 161\n",
      "File: how_to_prolong_lithium_ion_batteries.pdf, Chunks: 165\n",
      "File: liquid-batteries.txt, Chunks: 206\n",
      "File: outlook_on_lithium_batteries.pdf, Chunks: 278\n",
      "File: paper_battery_tech.pdf, Chunks: 477\n",
      "File: summary_britannica.pdf, Chunks: 558\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "for file in os.listdir('../texts'):\n",
    "    file_path = os.path.join('../texts', file)\n",
    "    if os.path.isfile(file_path):\n",
    "        try:\n",
    "            chunks += chunk_file(file_path)\n",
    "            print(f\"File: {file}, Chunks: {len(chunks)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e184c257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 558 embeddings.\n",
      "tensor([[-0.0093,  0.0307, -0.0964,  ..., -0.0519,  0.0797,  0.0123],\n",
      "        [-0.0262,  0.0354, -0.0795,  ..., -0.0707,  0.0807,  0.0245],\n",
      "        [-0.0099,  0.0234, -0.0970,  ..., -0.0655,  0.0765,  0.0050],\n",
      "        ...,\n",
      "        [-0.0930,  0.0909, -0.0533,  ..., -0.0308,  0.0004,  0.0326],\n",
      "        [-0.0776,  0.0843, -0.0835,  ..., -0.0349, -0.0131,  0.1084],\n",
      "        [-0.0792,  0.0708, -0.0515,  ..., -0.0400, -0.0076,  0.1469]])\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(chunks, convert_to_tensor=True)\n",
    "print(f\"Generated {len(embeddings)} embeddings.\")\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d0b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amogh\\AppData\\Local\\Temp\\ipykernel_17128\\2736467175.py:12: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QDRANT_URL = \"https://1ae2c6f5-15a4-49e9-af8d-96ab7348e31e.eu-central-1-0.aws.cloud.qdrant.io:6333\"\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")\n",
    "\n",
    "\n",
    "client = QdrantClient(\n",
    "    url=QDRANT_URL,\n",
    "    api_key=QDRANT_API_KEY,\n",
    ")\n",
    "collection_name = \"battery_chunks\"\n",
    "vector_size = embeddings.shape[1]\n",
    "\n",
    "client.recreate_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE)\n",
    ")\n",
    "\n",
    "points = [\n",
    "    PointStruct(id=i, vector=embeddings[i], payload=chunks[i])\n",
    "    for i in range(len(chunks))\n",
    "]\n",
    "\n",
    "client.upsert(collection_name=collection_name, points=points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6f1ad6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.7259\n",
      "File: paper_battery_tech.pdf\n",
      "\n",
      "Score: 0.7067\n",
      "File: paper_battery_tech.pdf\n",
      "\n",
      "Score: 0.6953\n",
      "File: paper_battery_tech.pdf\n"
     ]
    }
   ],
   "source": [
    "query = \"Paper battery technology\"\n",
    "query_vector = model.encode(query)\n",
    "\n",
    "response = client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=query_vector,\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "for point in response.points:\n",
    "    print(f\"\\nScore: {point.score:.4f}\")\n",
    "    print(f\"File: {point.payload.get('file')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c5e15c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What type of battery is BAT-0002?\"\n",
    "query_vector = model.encode(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3712bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=query_vector,\n",
    "    limit=20\n",
    ")\n",
    "\n",
    "retrieved_chunks = [point.payload.get(\"text\") for point in response.points if point.payload.get(\"text\")]\n",
    "context = \"\\n\\n\".join(retrieved_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9acec435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(context: str, query: str) -> str:\n",
    "    return f\"\"\"You are a technical expert.\n",
    "\n",
    "Use the following context to answer the user's question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Answer:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ddb6e4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_groq_llm(prompt, model=GROQ_MODEL, key=GROQ_API_KEY):\n",
    "    url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a technical expert.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6cba5abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: According to the provided context, BAT-0002 is a Li-ion battery.\n",
      "\n",
      "Score: 0.5829\n",
      "File: battery_technology_data.xlsx\n",
      "\n",
      "Score: 0.5747\n",
      "File: battery_technology_data.xlsx\n",
      "\n",
      "Score: 0.5737\n",
      "File: battery_technology_data.xlsx\n",
      "\n",
      "Score: 0.5687\n",
      "File: battery_technology_data.xlsx\n",
      "\n",
      "Score: 0.5667\n",
      "File: battery_technology_data.xlsx\n",
      "\n",
      "Score: 0.5607\n",
      "File: battery_technology_data.xlsx\n",
      "\n",
      "Score: 0.5590\n",
      "File: battery_technology_data.xlsx\n",
      "\n",
      "Score: 0.5549\n",
      "File: battery_technology_data.xlsx\n",
      "\n",
      "Score: 0.5527\n",
      "File: battery_technology_data.xlsx\n",
      "\n",
      "Score: 0.5482\n",
      "File: battery_technology_data.xlsx\n",
      "\n",
      "Score: 0.5385\n",
      "File: summary_britannica.pdf\n",
      "\n",
      "Score: 0.5339\n",
      "File: summary_britannica.pdf\n",
      "\n",
      "Score: 0.5221\n",
      "File: summary_britannica.pdf\n",
      "\n",
      "Score: 0.5177\n",
      "File: summary_britannica.pdf\n",
      "\n",
      "Score: 0.5157\n",
      "File: battery_tech_unique_data.json\n",
      "\n",
      "Score: 0.5130\n",
      "File: summary_britannica.pdf\n",
      "\n",
      "Score: 0.5126\n",
      "File: battery_tech_unique_data.json\n",
      "\n",
      "Score: 0.5124\n",
      "File: summary_britannica.pdf\n",
      "\n",
      "Score: 0.5090\n",
      "File: battery_tech_unique_data.json\n",
      "\n",
      "Score: 0.5056\n",
      "File: battery_tech_unique_data.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = generate_prompt(context, query)\n",
    "answer = ask_groq_llm(prompt, model=GROQ_MODEL, key=GROQ_API_KEY)\n",
    "print(f\"\\nAnswer: {answer}\\n\")\n",
    "for point in response.points:\n",
    "    score = point.score\n",
    "    file = point.payload.get(\"file\", \"Unknown\")\n",
    "    print(f\"Score: {score:.4f}\\nFile: {file}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
